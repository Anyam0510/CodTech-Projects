{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\uddea ETL Pipeline using Pandas & Scikit-learn\n", "This notebook performs an end-to-end ETL process: Extract, Transform, Load."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n", "from sklearn.impute import SimpleImputer\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace with your actual path\n", "DATA_PATH = \"raw_data.csv\"\n", "\n", "# Load data\n", "df = pd.read_csv(DATA_PATH)\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Identify numerical and categorical columns\n", "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n", "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n", "\n", "print(\"Numerical Columns:\", num_cols)\n", "print(\"Categorical Columns:\", cat_cols)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Numerical pipeline\n", "num_pipeline = Pipeline([\n", "    ('imputer', SimpleImputer(strategy='mean')),\n", "    ('scaler', StandardScaler())\n", "])\n", "\n", "# Categorical pipeline\n", "cat_pipeline = Pipeline([\n", "    ('imputer', SimpleImputer(strategy='most_frequent')),\n", "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n", "])\n", "\n", "# Combine them\n", "full_pipeline = ColumnTransformer([\n", "    ('num', num_pipeline, num_cols),\n", "    ('cat', cat_pipeline, cat_cols)\n", "])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit and transform\n", "transformed_data = full_pipeline.fit_transform(df)\n", "\n", "# Convert to DataFrame\n", "transformed_df = pd.DataFrame(\n", "    transformed_data.toarray() if hasattr(transformed_data, \"toarray\") else transformed_data\n", ")\n", "\n", "transformed_df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["OUTPUT_PATH = \"processed_data.csv\"\n", "transformed_df.to_csv(OUTPUT_PATH, index=False)\n", "\n", "print(f\"\u2705 Processed data saved to: {OUTPUT_PATH}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import joblib\n", "\n", "# Save the pipeline object\n", "joblib.dump(full_pipeline, \"etl_pipeline_model.pkl\")\n", "print(\"\ud83d\udcbe Pipeline model saved as 'etl_pipeline_model.pkl'\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}